{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice, choices\n",
    "from string import ascii_lowercase, digits\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.stats.proportion import multinomial_proportions_confint, proportion_confint\n",
    "\n",
    "from scipy.stats import binom\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sisson_glaz(sample_freqs, sample_probs, word_list):\n",
    "    sis = pd.DataFrame(multinomial_proportions_confint(sample_freqs, method='sison-glaz'), \n",
    "                   columns=['ci_lower','ci_upper'])\n",
    "    sis['exp_method'] = 'sison-glaz'\n",
    "    sis['word'] = word_list\n",
    "    sis['param_probs'] = sample_probs\n",
    "    sis['sample_probs'] = sample_probs\n",
    "    return sis[['word', 'sample_probs', 'param_probs', 'exp_method', 'ci_lower', 'ci_upper']]\n",
    "\n",
    "\n",
    "def gt_orlitsky(sample, word_list):\n",
    "    counts = pd.Series(sample).value_counts().reindex(word_list , fill_value=0)\n",
    "    counts_of_counts = counts.value_counts()\n",
    "    p = {}\n",
    "    for c in (counts_of_counts.index):\n",
    "        c_o_c_1 = counts_of_counts[c+1] if c+1 in counts_of_counts else 0\n",
    "        if c > c_o_c_1:\n",
    "            p[c] = (c/counts.sum())\n",
    "        else:\n",
    "            p[c] = (c_o_c_1+1) * (c+1) / (counts.sum() * counts_of_counts[c])\n",
    "    new_p = counts.map(p)\n",
    "    return list(new_p / new_p.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zipf_dist_probs(zipf_param, exp_alphabet_size):\n",
    "    ranks = np.arange(1, exp_alphabet_size+1)\n",
    "    weights = ranks ** (-zipf_param)\n",
    "    exp_probs = (weights / sum(weights))\n",
    "    return exp_probs\n",
    "\n",
    "\n",
    "def get_uniform_dist_probs(size):\n",
    "    probs = np.array([1]*size) / size\n",
    "    return probs\n",
    "\n",
    "\n",
    "def get_step_dist_probs(exp_alphabet_size):\n",
    "    probs = [1/(2*exp_alphabet_size)]*(int(exp_alphabet_size/2)) + [3/(2*exp_alphabet_size)]*(int(exp_alphabet_size/2))\n",
    "    return probs\n",
    "\n",
    "\n",
    "def get_word_list(size):\n",
    "    chars = ascii_lowercase + digits\n",
    "    word_list = [''.join(choice(chars) for _ in range(3)) for _ in range(size*2)]\n",
    "    word_list = list(set(word_list))[:size]\n",
    "    word_list.sort()\n",
    "    return word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_ci_framwork(boot_list, ci_method, param_func_probs, sample_probs, sample_size, corrected_confidence,\n",
    "                         num_of_bootstrap_smaples):\n",
    "    \n",
    "    if ci_method == 'good_bootstrap':\n",
    "        max_probs_list = []\n",
    "        for arr in boot_list: \n",
    "            if np.any(arr == 0):\n",
    "                arr_prob = arr == 0\n",
    "                max_prob = np.array(param_func_probs)[arr_prob].max()\n",
    "                max_probs_list.append(max_prob)\n",
    "        ci_bound_for_zero = np.quantile(max_probs_list,corrected_confidence, interpolation='lower')\n",
    "   \n",
    "    elif ci_method == 'rule_of_three':\n",
    "        ci_bound_for_zero = -np.log(1-corrected_confidence)/sample_size\n",
    "   \n",
    "    ci_lower_list = [0]*len(sample_probs)\n",
    "    ci_upper_list = [0]*len(sample_probs)\n",
    "    \n",
    "    for i in range(len(sample_probs)):\n",
    "        if sample_probs[i] == 0:\n",
    "            ci_lower_list[i] = 0\n",
    "            ci_upper_list[i] = ci_bound_for_zero\n",
    "        else:\n",
    "            ci_lower_list[i], ci_upper_list[i] = proportion_confint(sample_probs[i]*sample_size, sample_size, \n",
    "                                                                    (1-corrected_confidence), method=\"beta\")\n",
    "    return ci_lower_list, ci_upper_list\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci(boot_list, ci_method, probs, sample_size, corrected_confidence, num_of_bootstrap_smaples, sample_probs):\n",
    "    boot_pct_ci = pd.DataFrame()\n",
    "    boot_pct_ci['param_probs'] = probs\n",
    "    \n",
    "    if ci_method == 'percentile':\n",
    "        boot_pct_ci['ci_lower'] = np.quantile(boot_list,(1-corrected_confidence)/2, axis=0)\n",
    "        boot_pct_ci['ci_upper'] = np.quantile(boot_list,(1+corrected_confidence)/2, axis=0)\n",
    "\n",
    "    elif ((ci_method == 'good_bootstrap') | (ci_method == 'rule_of_three')):\n",
    "        boot_pct_ci['ci_lower'], boot_pct_ci['ci_upper'] = combined_ci_framwork(boot_list, ci_method, probs, \n",
    "                                                                  sample_probs, sample_size, \n",
    "                                                                  corrected_confidence, num_of_bootstrap_smaples)\n",
    "    return boot_pct_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parametric_bootstrap(sample_words_list, sample_probs, word_index, sample_size, num_of_bootstrap_smaples, \n",
    "                             param_dist_func, ci_method='percentile',confidence=.95, bonferroni_correction=True):\n",
    "    \n",
    "    bonf_corrected_alpha = (1-confidence)/len(word_index)\n",
    "    corrected_confidence = 1-(bonf_corrected_alpha) if bonferroni_correction else confidence\n",
    "    probs = param_dist_func(sample_words_list, word_index)\n",
    "    \n",
    "    boot_arr = default_rng().multinomial(sample_size, probs, size=num_of_bootstrap_smaples)\n",
    "    boot_list = list(boot_arr / boot_arr.sum(axis=1, keepdims=True))\n",
    "\n",
    "    boot_pct_ci = get_ci(boot_list, ci_method, probs, sample_size, corrected_confidence,\n",
    "                        num_of_bootstrap_smaples, sample_probs)\n",
    "    \n",
    "    boot_pct_ci['exp_method'] = ci_method \n",
    "\n",
    "    boot_pct_ci['word'] = word_index\n",
    "    boot_pct_ci['sample_probs'] = sample_probs\n",
    "\n",
    "    return boot_pct_ci[['word', 'sample_probs', 'param_probs', 'exp_method', 'ci_lower', 'ci_upper']].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(sample_size, probs, word_list, dictionary, num_of_bootstrap_smaples, iteration=None):\n",
    "    if iteration % 10 == 0: \n",
    "        print('iteration {}'.format(iteration))\n",
    "    \n",
    "    samp_exp = default_rng().multinomial(sample_size, probs, size=1).flatten()\n",
    "\n",
    "    our_sample_exp = pd.DataFrame(np.transpose(samp_exp), index=word_list, columns=['samp'])\n",
    "    our_sample_exp['probs'] = our_sample_exp['samp'] / our_sample_exp['samp'].sum()\n",
    "    our_sample_raw_exp = list(np.repeat(word_list, our_sample_exp.samp))\n",
    "    \n",
    "    sis = sisson_glaz(our_sample_exp.samp, our_sample_exp['probs'].to_list(), word_list)\n",
    "    \n",
    "    good_bootstrap = run_parametric_bootstrap(our_sample_raw_exp,our_sample_exp['probs'].to_list(), word_list, \n",
    "                                              sample_size, num_of_bootstrap_smaples, \n",
    "                                              gt_orlitsky, ci_method='good_bootstrap')\n",
    "    rot = run_parametric_bootstrap(our_sample_raw_exp,our_sample_exp['probs'].to_list(), word_list, \n",
    "                                   sample_size, num_of_bootstrap_smaples, \n",
    "                                   gt_orlitsky, ci_method='rule_of_three')\n",
    "    \n",
    "    res =pd.concat([sis, good_bootstrap, rot], ignore_index=True)\n",
    "    res.loc[res['ci_lower'] < 0, 'ci_lower'] = 0\n",
    "    res.loc[res['ci_upper'] > 1, 'ci_upper'] = 1\n",
    "    res['ci_length'] = res['ci_upper'] - res['ci_lower']\n",
    "    res['log_ci_length'] = np.log(res['ci_length'])\n",
    "    res['exp_num'] = iteration \n",
    "    res['true_prob'] = res['word'].map(dictionary)\n",
    "    res['log_true_prob'] = np.log(res['true_prob'])\n",
    "    res['in_ci'] = (res['true_prob'] >= res['ci_lower']) & \\\n",
    "                       (res['true_prob'] <= res['ci_upper'])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_alphabet_size = 100\n",
    "\n",
    "exp_probs = get_zipf_dist_probs(1.01, exp_alphabet_size)\n",
    "exp_sample_size = 50\n",
    "\n",
    "chars = ascii_lowercase + digits\n",
    "exp_word_list = [''.join(choice(chars) for _ in range(3)) for _ in range(exp_alphabet_size*2)]\n",
    "exp_word_list = list(set(exp_word_list))[:exp_alphabet_size]\n",
    "exp_word_list.sort()\n",
    "exp_dictionary = dict(zip(exp_word_list, exp_probs))\n",
    "\n",
    "exp_bootstrap_smaples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 10\n",
      "iteration 20\n",
      "iteration 30\n",
      "iteration 40\n",
      "iteration 50\n",
      "iteration 60\n",
      "iteration 70\n",
      "iteration 80\n",
      "iteration 90\n",
      "\n",
      " *********** process run time 0.37437983751297 minutes ***********\n"
     ]
    }
   ],
   "source": [
    "\n",
    "experiment_runs = 100\n",
    "pool = Pool(10)\n",
    "func = partial(run_experiment, exp_sample_size, exp_probs, exp_word_list, exp_dictionary, exp_bootstrap_smaples)\n",
    "\n",
    "start_time = time.time()\n",
    "pooled_results = pool.starmap(func, zip(range(experiment_runs)))\n",
    "pool.close()\n",
    "pool.join()\n",
    "print(\"\\n *********** process run time {} minutes ***********\".format((time.time() - start_time)/60))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
